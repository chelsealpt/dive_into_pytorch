## 梯度消失与爆炸 环境变量（偏移）
[toc]
### 梯度消失与梯度爆炸

tanh、sigmoid等存在饱和的激活函数会出现梯度消失
在循环神经网络中使用BPTT反向传播算法，也会出现梯度消失或梯度爆炸

![09c5d22375a215275df16a9cc7032465.png](en-resource://database/499:1)

### 考虑环境因素
#### 协变量偏移
网络在一个给定训练集上测试，那么该网络已经学习了一个数据分布。来了一个新的测试集，其分布不同于原先训练集，这个网络在这个测试集上表现就不好了，说明协变量漂移发生了。 这篇博客举了一个例子，比较形象

>见winter_study/讲解/What Is Covariate Shift_ - Saeed Izadi - Medium
>![69000215822fde45f33c8e65d27b4e20.png](en-resource://database/505:1)
#### 标签偏移
标签偏移可以简单理解为测试时出现了训练时没有的标签
#### 概念偏移

即标签本身的定义发生变化的情况
举例说明如下 关于coke的简单术语的定义也会发生相当大的概念转变
![1a7fba4da5db15d0026cfdf14d50bf79.png](en-resource://database/507:1)


* 一些例题




![2f01d8c759ddd515dfce8f23ced0e57d.png](en-resource://database/501:1)

* 解释：模型是在冬季部署，所以用的是冬季的数据作为训练集，在夏季使用，相当于而测试集是夏季的物品

![78e0a7a387df407b21bb1eb9f00e2a15.png](en-resource://database/503:1)

