### 过拟合欠拟合及解决方案
[TOC]
#### 1.模型选择、过拟合和欠拟合

##### 1.1K折交叉验证

*  当训练数据不够用时

* 我们把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他K-1个子数据集来训练模型
* 我们对这K次训练误差和验证误差分别求平均。

##### 2.过拟合和欠拟合

(1) 一类是模型无法得到较低的误差，我们将这一现象称作**欠拟合**（underfitting）

(2)训练误差较低但是泛化误差依然较高，二者相差较大，我们称该现象为**过拟合**（overfitting）

>
训练误差（training error）和**泛化误差**（generalization error）。通俗来讲，前者指模型在训练数据集上表现出的误差，后者指模型在任意一个**测试数据**样本上表现出的误差的期望


* **模型复杂度**过低容易发生欠拟合
* 如果训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。
* 泛化误差不会随训练数据集里样本数量增加而增大；通常希望**训练数据集大一些**，特别是在模型复杂度较高时，例如层数较多的深度学习模型

![e5956a9cbd0ce762648fadcedf5faf3f.png](en-resource://database/489:1)

#### 2.防止过拟合方法
##### 1..权重衰减

* 权重衰减等价于 L2 范数正则化（regularization）
* 正则化通过为模型损失函数添加惩罚项使学出的**模型参数值较小**，是应对过拟合的常用手段
 ![3362fb6242d038478e95d4c4f3532353.png](en-resource://database/491:1)

* 对权重参数衰减，**不对偏差参数衰减**
##### 2.丢弃法

* 隐藏单元将有一定概率被丢弃掉。设丢弃概率为p，那么有p的概率hi会被清零，有1−p的概率hi会除以1−p做拉伸
* 丢弃法不改变其输入的期望值
* 在测试模型时，我们为了拿到更加确定性的结果，一般不使用丢弃法
